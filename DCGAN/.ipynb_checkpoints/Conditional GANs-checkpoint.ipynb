{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "676437d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    The following is a PyTorch Implementation of a Conditional GAN\n",
    "    This GAN leverages DCGAN architecture in the generator and the \n",
    "    discriminator\n",
    "'''\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "93d3175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    We use DCGAN discriminator and generator in this network. The post related to \n",
    "    DCGAN covers the DCGAN specifics in more detail. Here I will only highlight the \n",
    "    parts which are relevant to the Conditional GAN. \n",
    "'''\n",
    "\n",
    "class DCGAN_Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, featmap_dim=64, n_channel=1,cond_size = 10,batch_size = 128):\n",
    "        super(DCGAN_Discriminator, self).__init__()\n",
    "        self.featmap_dim = featmap_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.main = nn.Sequential(\n",
    "                    #second pass, in dim 1 x 32 x 32\n",
    "                    nn.Conv2d(2,featmap_dim,4,2,1,bias = False), \n",
    "                    nn.LeakyReLU(0.2,inplace = True), \n",
    "                    #third pass, ft.dim*2 x 16 x 16 \n",
    "                    nn.Conv2d(featmap_dim,featmap_dim*2,4,2,1,bias = False), \n",
    "                    nn.BatchNorm2d(featmap_dim*2),\n",
    "                    nn.LeakyReLU(0.2,inplace = True), \n",
    "                    #fourth pass, ft.dim*4 x 8 x 8 \n",
    "                    nn.Conv2d(featmap_dim*2,featmap_dim*4,4,2,1,bias = False), \n",
    "                    nn.BatchNorm2d(featmap_dim*4),\n",
    "                    nn.LeakyReLU(0.2,inplace = True),\n",
    "                    #fifth pass, ft.dim*2 x 4 x 4 \n",
    "                    nn.Conv2d(featmap_dim*4,1,4,1,0,bias = False), \n",
    "                    nn.Sigmoid() \n",
    "                    )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            We need to define the following embedding to embed the MNIST class label into \n",
    "            a feature map layer. We do this by passing the label through an embedding to\n",
    "            bring it up to the noise dimension. Then we pass it through dense linear layer\n",
    "        '''\n",
    "        self.embed = nn.Sequential(nn.Embedding(10,noise_dim),nn.Linear(noise_dim,32*32))\n",
    "\n",
    "    def forward(self, x,label):\n",
    "        \"\"\"\n",
    "        Strided convulation layers,\n",
    "        Batch Normalization after convulation but not at input layer,\n",
    "        LeakyReLU activation function with slope 0.2.\n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "            Embed the label and concatenate the feature maps \n",
    "        '''\n",
    "        \n",
    "        embedded_label = torch.reshape(self.embed(label), x.shape)\n",
    "        x=torch.cat((x,embedded_label),dim=1)\n",
    "        \n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class DCGAN_Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, featmap_dim=128, n_channel=1, noise_dim=100 ,cond_size = 10, batch_size = 128):\n",
    "        super(DCGAN_Generator, self).__init__()\n",
    "        self.featmap_dim = featmap_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.noise_dim  = noise_dim\n",
    "        self.main = nn.Sequential(\n",
    "                    ##input batch_size x 2 x 1 x noise_dim tensor\n",
    "                    ##first pass, state size 4x4 \n",
    "                   # nn.ConvTranspose2d(512+1, featmap_dim*8,4,1,0,bias = False), \n",
    "                    #nn.BatchNorm2d(featmap_dim*8), \n",
    "                   # nn.ReLU(True), \n",
    "                    ##second pass, state size 8x8\n",
    "                    nn.ConvTranspose2d(512+1,featmap_dim*4,4,2,1,bias = False), \n",
    "                    nn.BatchNorm2d(featmap_dim*4), \n",
    "                    nn.ReLU(True), \n",
    "                    ##third pass, state size 16,16\n",
    "                    nn.ConvTranspose2d(featmap_dim*4,featmap_dim*2,4,2,1,bias = False), \n",
    "                    nn.BatchNorm2d(featmap_dim*2), \n",
    "                    nn.ReLU(True), \n",
    "                    ##fourth pass, state size 32,32 \n",
    "                    nn.ConvTranspose2d(featmap_dim*2,1,4,2,1,bias = False),\n",
    "                    nn.Tanh() \n",
    "                    )\n",
    "        \n",
    "        '''\n",
    "            Here we need to embed the label for the image as well as generate feature \n",
    "            maps from both the embedding and the latent code. These feature maps are \n",
    "            then concatenated. \n",
    "        '''\n",
    "        \n",
    "        self.embed = nn.Sequential(nn.Embedding(10,noise_dim),nn.Linear(noise_dim,4*4))\n",
    "        self.latent_encode = nn.Sequential(nn.Linear(noise_dim, 512*4*4),nn.ReLU(True))\n",
    "        \n",
    "    def forward(self, x,label):\n",
    "        \"\"\"\n",
    "        Project noise to featureMap * width * height,\n",
    "        Batch Normalization after convulation but not at output layer,\n",
    "        ReLU activation function.\n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "            Embed, pass into feature maps, then concatenate\n",
    "        '''\n",
    "        embedded_label= torch.reshape(self.embed(label),(x.shape[0],1,4,4))\n",
    "        z = torch.reshape(self.latent_encode(x),(x.shape[0], 512,4,4))                           \n",
    "        x =torch.cat((z,embedded_label),dim=1)\n",
    "        return self.main(x) \n",
    "\n",
    "\n",
    "def weights_init(m): \n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1: \n",
    "        nn.init.normal_(m.weight.data,0.0,0.02)\n",
    "    elif classname.find('BatchNorm') != -1: \n",
    "        nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "        nn.init.constant_(m.bias.data,0)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f94dce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data for MNIST \n",
    "transform = transforms.Compose([transforms.Resize(32),transforms.ToTensor(),transforms.Normalize(0,1)])\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = True, \n",
    "    transform =   transform,\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform =  transform\n",
    ")\n",
    "                                \n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "loaders = {'train': torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True,num_workers = 1, pin_memory = True), \n",
    "          'test' : torch.utils.data.DataLoader(test_data, batch_size = batch_size, shuffle = True, num_workers = 1, pin_memory = True)}\n",
    "\n",
    "\n",
    "#define model \n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3317f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "'''\n",
    "Training Loop\n",
    "'''\n",
    "\n",
    "\n",
    "def train_GAN(epochs, discriminator, generator, loaders,dOptim, gOptim, dLoss, gLoss, disc_scheduler, gen_scheduler,noise_dim=100,batch_size = 500): \n",
    "    torch.cuda.empty_cache()\n",
    "    total_step = len(loaders['train']) \n",
    "    \n",
    "    #here we define the fixed noise vector\n",
    "    dim_fixed_noise = 5\n",
    "    fixed_noise = torch.randn(dim_fixed_noise,noise_dim,1,1,device = device)\n",
    "    fixed_noise = torch.flatten(fixed_noise,start_dim =1)\n",
    "    \n",
    "    time_diff = [] \n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        TS  = time.time() \n",
    "        for i , data in enumerate(loaders['train'],0): \n",
    "            #loads true inputs and labels into cuda \n",
    "            true_inputs,to_encode = data\n",
    "            true_inputs = true_inputs.cuda()\n",
    "            to_encode = to_encode.cuda()\n",
    "            \n",
    "            #get actual batch size (dataset might not be cut evenly) \n",
    "            act_batch_size = len(true_inputs)\n",
    "            '''\n",
    "                create labels for the real and fake targets\n",
    "            '''\n",
    "            real_label = torch.from_numpy(np.ones(act_batch_size).astype(np.float32)).to(device)\n",
    "            fake_label = torch.from_numpy(np.zeros(act_batch_size).astype(np.float32)).to(device)\n",
    "            \n",
    "            \n",
    "            t1 = time.time() \n",
    "            \n",
    "            '''\n",
    "                Discriminator Training\n",
    "            '''\n",
    "            \n",
    "            #training Discriminator network on real data \n",
    "            discriminator.zero_grad()\n",
    "            output =  discriminator(true_inputs,to_encode).view(-1)\n",
    "            errD_real = dLoss(output, real_label) \n",
    "            errD_real.backward() \n",
    "            D_x = output.mean().item() \n",
    "            \n",
    "            #train D with fake batch \n",
    "            \n",
    "            #first need to generate false outputs\n",
    "            noise = torch.randn(act_batch_size,noise_dim,device = device)\n",
    "            raw_labels = torch.randint(0,10,(1,act_batch_size),device =device)[0]\n",
    "            \n",
    "            false_inputs = generator(noise,raw_labels)\n",
    "            \n",
    "            #training on false inputs\n",
    "            output = discriminator(false_inputs,raw_labels).view(-1) \n",
    "            errD_fake = dLoss(output,fake_label) \n",
    "            errD_fake.backward(retain_graph = True) \n",
    "            D_G_z1 = output.mean().item() \n",
    "            #total D error \n",
    "            errD = (errD_real + errD_fake)/2 \n",
    "            \n",
    "            '''\n",
    "                Generator Training\n",
    "            '''\n",
    "            \n",
    "            #now train G \n",
    "            generator.zero_grad()\n",
    "            output = discriminator(false_inputs,raw_labels).view(-1) \n",
    "            #output = discriminator(false_inputs).view(-1) \n",
    "            errG = gLoss(output,real_label) \n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item() \n",
    "            #update G and D\n",
    "            \n",
    "            dOptim.step() \n",
    "            gOptim.step() \n",
    "            \n",
    "            '''\n",
    "               Sample output statements \n",
    "            '''\n",
    "            t2 = time.time()    \n",
    "            time_diff.append((t2-t1)/total_step) \n",
    "            if (i+1) % (total_step/2) == 0: \n",
    "                print('Epoch [{}/{}], Step [{}/{}], Discriminator Loss: {:.8f}, Generator Loss: {:.8f}, Pass Rates (real/fake): {:.8f} {:.8f}' \n",
    "                       .format(epoch + 1, epochs, i + 1, total_step, errD.item(),errG.item(), D_x,D_G_z2))\n",
    "                resize_transform = transforms.Resize(64)\n",
    "                \n",
    "                full_mat = np.zeros([64*dim_fixed_noise,640])\n",
    "              \n",
    "\n",
    "                for j in range(10): \n",
    "                    fixed_labels = (torch.ones((1,dim_fixed_noise),device = device)*j).type(torch.int64)\n",
    "                    fixed_encoded_labels = torch.squeeze(F.one_hot(fixed_labels,num_classes= 10)).type(torch.FloatTensor).cuda()\n",
    "                    \n",
    "                    test_output = generator(fixed_noise, fixed_labels)\n",
    "                    test_output = resize_transform(torch.reshape(test_output,(dim_fixed_noise, 32,32)))#resize output \n",
    "                    full_mat[:,j*64:(j+1)*64] = test_output.view(dim_fixed_noise*64,64).cpu().detach().numpy()\n",
    "                    \n",
    "                full_mat = np.where(full_mat>0, full_mat, 0)                \n",
    "                img = Image.fromarray(np.uint8(full_mat * 255) , 'L')\n",
    "                print('test Image: \\n')\n",
    "                display(img)\n",
    "        TE = time.time() \n",
    "        \n",
    "        print('average step time: {:.8f}, total time for epoch: {:2.4f}'.format(sum(time_diff), (TE-TS)/total_step ))\n",
    "        time_diff = []\n",
    "        disc_scheduler.step() \n",
    "        gen_scheduler.step()\n",
    "    return generator, discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d5acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "noise_dim = 256\n",
    "g_net = DCGAN_Generator(noise_dim=noise_dim) \n",
    "d_net = DCGAN_Discriminator( ) \n",
    "g_net.cuda() \n",
    "d_net.cuda() \n",
    "\n",
    "\n",
    "g_net.apply(weights_init) \n",
    "d_net.apply(weights_init)\n",
    "\n",
    "dis_loss = nn.MSELoss() \n",
    "gen_loss = nn.MSELoss() \n",
    "#dis_loss = nn.BCELoss() \n",
    "#gen_loss = nn.BCELoss() \n",
    "dis_optim = optim.Adam(d_net.parameters(), lr = .0001,betas=(0.5, 0.99))\n",
    "#dis_optim = optim.RMSprop(d_net.parameters(), lr = .0005, centered = True)\n",
    "gen_optim = optim.Adam(g_net.parameters(), lr = .001,betas=(0.5, 0.99))\n",
    "#gen_optim = optim.RMSprop(g_net.parameters(),lr = .0001)\n",
    "#dis_optim = optim.SGD(d_net.parameters(), lr = .1,momentum = .9, weight_decay = .0001)\n",
    "#gen_optim = optim.SGD(g_net.parameters(), lr = .1,momentum = 0, weight_decay = .0001)\n",
    "schedulerD =torch.optim.lr_scheduler.StepLR(dis_optim, step_size = 10, gamma=.1, verbose=False)\n",
    "schedulerG =torch.optim.lr_scheduler.StepLR(gen_optim, step_size = 10, gamma=.1, verbose=False)\n",
    "\n",
    "G, D = train_GAN(40,d_net,g_net, loaders, dis_optim, gen_optim, dis_loss, gen_loss,schedulerD, schedulerG,noise_dim=noise_dim, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88981dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Save trained Model\n",
    "'''\n",
    "torch.save(G.state_dict(), 'cGAN_gen.model') \n",
    "torch.save(D.state_dict(), 'cGAN_dis.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
